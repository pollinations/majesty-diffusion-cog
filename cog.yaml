# Configuration for Cog ⚙️
# Reference: https://github.com/replicate/cog/blob/main/docs/yaml.md

build:
  # set to true if your model requires a GPU
  gpu: true

  # a list of ubuntu apt packages to install
  system_packages:
    - "aria2"
    - "ffmpeg"

  # python version in the form '3.8' or '3.8.12'
  python_version: "3.7"

  # a list of packages in the format <package-name>==<version>
  python_packages:
    - "numpy==1.21.6"
    - "torch==1.11.0"
    - "torchvision==0.12.0"
    - "omegaconf==2.2.2"
    - "pytorch-lightning==1.6.4"
    - "torch-fidelity==0.3.0"
    - "einops==0.4.1"
    - "transformers==4.19.2"
    - "open_clip_torch==1.2.1"
    - "autokeras==1.0.19"
  
  # commands run after the environment is setup
  run:
    - mkdir -p /content/models/
    - git clone https://github.com/multimodalart/latent-diffusion --branch 1.6
    - git clone https://github.com/CompVis/taming-transformers
    - git clone https://github.com/TencentARC/GFPGAN
    - curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash
    - apt-get install git-lfs
    - git lfs install
    - git lfs clone https://huggingface.co/datasets/multimodalart/latent-majesty-diffusion-settings
    - git lfs clone https://github.com/LAION-AI/aesthetic-predictor
    - pip install -e ./taming-transformers
    - pip install omegaconf>=2.0.0 pytorch-lightning>=1.0.8 torch-fidelity einops
    - pip install transformers
    - pip install dotmap
    - pip install resize-right
    - pip install piq
    - pip install lpips
    - pip install basicsr
    - pip install facexlib
    - pip install realesrgan
    - git clone https://github.com/apolinario/Multi-Modal-Comparators --branch gradient_checkpointing
    - pip install poetry
    - cd Multi-Modal-Comparators; poetry build; cd ..
    - cd Multi-Modal-Comparators; pip install dist/mmc*.whl; cd ..
    - python Multi-Modal-Comparators/src/mmc/napm_installs/__init__.py
    - wget -O /content/models/latent_diffusion_txt2img_f8_large.ckpt https://ommer-lab.com/files/latent-diffusion/nitro/txt2img-f8-large/model.ckpt --no-check-certificate
    - wget -O /content/models/txt2img-f8-large-jack000-finetuned-fp16.ckpt https://huggingface.co/multimodalart/compvis-latent-diffusion-text2img-large/resolve/main/txt2img-f8-large-jack000-finetuned-fp16.ckpt --no-check-certificate
    - wget -O /content/models/ongo.pt https://huggingface.co/laion/ongo/resolve/main/ongo.pt
    - wget -O /content/models/erlich.pt https://huggingface.co/laion/erlich/resolve/main/model/ema_0.9999_120000.pt
    - wget -O /content/models/ava_vit_l_14_336_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_336_linear.pth
    - wget -O /content/models/sa_0_4_vit_l_14_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_l_14_linear.pth
    - wget -O /content/models/ava_vit_l_14_linear.pth https://models.nmb.ai/majesty/ava_vit_l_14_linear.pth
    - wget -O /content/models/ava_vit_b_16_linear.pth https://the-eye.eu/public/AI/models/v-diffusion/ava_vit_b_16_linear.pth
    - wget -O /content/models/sa_0_4_vit_b_16_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_16_linear.pth
    - wget -O /content/models/sa_0_4_vit_b_32_linear.pth https://models.nmb.ai/majesty/sa_0_4_vit_b_32_linear.pth
    - wget -O /content/models/openimages_512x_png_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/openimages_512x_png_embed224.npz
    - wget -O /content/models/imagenet_512x_jpg_embed224.npz https://github.com/nshepperd/jax-guided-diffusion/raw/8437b4d390fcc6b57b89cedcbaf1629993c09d03/data/imagenet_512x_jpg_embed224.npz
    - wget -O /content/models/GFPGANv1.3.pth https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth
    - cp /content/models/GFPGANv1.3.pth GFPGAN/experiments/pretrained_models/GFPGANv1.3.pth

        
        # optional final step:
        #poe napm_installs
        

# predict.py defines how predictions are run on your model
predict: "predict.py:Predictor"
